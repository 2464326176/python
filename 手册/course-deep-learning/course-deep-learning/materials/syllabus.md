#第一章 初识深度学习#

### 重点

1. 理解DL的起源、发展、作用以及对我们的意义。
2. 明了DL、ANN、MLP的关系。

### 难点

 无

### 教学目标

1. 掌握深度学习相关术语的意义、符号表示。
2. 掌握深度学习模型的优势。
3. 了解DL的用途。

# 第二章 构造神经网络

### 重点

1. 神经元的数学表达。
2. 常见激活函数的作用与意义。
3. python简单时间ANN。
4. 利用ANN解决XOR问题。

### 难点

1. 解决XOR问题的意义。

### 教学目标

1. 理解人工神经元的解构，并能够自己实现人工神经元。
2. 理解全连接神经网络的结构。
3. 解决XOR问题的意义。

# 第三章 ANN的自我学习

### 重点

1. 梯度下降法的意义。
2. 反向传播算法的优势。
3. 过拟合与欠拟合的解决方法。

### 难点

1. 反向传播算法的优势。
2. 非凸函数的存在局部极小值的解决方案。

### 教学目标

1. 明了均方误差代价函数的意义。
2. 明了梯度下降法的意义。
3. 明了参数初始化的基本方法。
4. 明了参数更新规则。
5. 学会计算神经网络的参数规模。
6. 了解神经网络的输入层与输出层分布处理输入与输出的基本方法。
7. 了解过拟合与欠拟合以及解决方案。

# 第四章 反向传播算法

### 重点

1. 反向传播算法的推导过程。
2. 梯度不稳定的缘由和解决方案。

### 难点

1. 反向传播算法的推导过程。

### 教学目标

1. 理解并掌握反向传播算法的推导过程。
2. 明了梯度不稳定的缘由。
3. 明了均方误差代价函数的优缺点。

# 第五章 输出层与代价函数

### 重点

1. sigmoid、softmax等激活函数的作用。
2. 均方误差代价函数、交叉熵代价函数以及对数似然代价函数的使用范围。

### 难点

1. 极大似然代价函数的推导。

### 教学目标

1. 掌握sigmoid激活函数的公式、作用、使用场景。
2. 掌握softmax激活函数的公式、作用、使用场景。
3. 掌握均方误差代价函数的使用场景。
4. 掌握交叉熵代价函数的使用场景。
5. 掌握对数似然代价函数的使用场景。

# 第六章 自编码器

### 重点

1. 自编码器的结构、训练方法。
2. 普通自编码器的用途。
3. 降噪自编码器的训练方法与用途。
4. 栈式自编码器的训练方法与意义

### 难点

1. 自编码器的意义。
2. 降噪自编码器的训练方法
3. 栈式自编码器的训练。

### 教学目标

1. 理解并掌握自编码器的结构、训练方法、使用场景。
2. 理解并掌握降噪自编码器的训练方法与使用场景。
3. 理解并掌握栈式自自编码器的训练方法与使用场景。

# 第七章 特征表达与稀疏自编码器

### 重点

1. 特征的表现形式。
2. 模型如何输入不同类型样本。
3. 稀疏激活性的优势。
4. 稀疏自编码器的结构
5. 隐藏层神经元激活度的衡量方法。
6. KL散度的用法与意义。

### 难点

1. 隐藏层神经元激活度的衡量方法。
2. 带稀疏性约束的代价函数。

### 教学目标

1. 理解并掌握特征的概念。
2. 掌握KL散度的公式写法与意义。
3. 理解并掌握稀疏性约束的方法。

# 第八章 卷积神经网络（一）

### 重点

1. 局部感知的意义。
2. 卷积的作用。
3. 卷积特征图的大小的计算方法。
4. 多核卷积的过程。
5. 下采样的方法。

### 难点

1. 卷积与池化的步长。
2. 多核卷积中卷积核的数量。

### 教学目标

1. 理解局部感知背后的原理。
2. 理解卷积与局部感知的关系。
3. 学会计算特征图的大小。
4. 理解多核卷积中计算卷积核数量的方法。
5. 掌握池化的方法。

# 第九章 卷积神经网络（二）

### 重点

1. 卷积与池化计算的详细过程。
2. 理解通道的概念。
3. 多通道卷积的方法。
4. 卷积与池化边界处理的方法。
5. 卷积层与池化层的灵活应用。

### 难点

1. 多通道卷积的方法。
2. 卷积与池化边界处理的计算方法。

### 教学目标

1. 掌握卷积与池化详细计算的过程。
2. 掌握多通道卷积的计算过程。
3. 掌握边界处理的两种方法。
4. 掌握边界处理中边界计算的方法。

# 第十章 卷积神经网络（三）

### 重点

1. 卷积神经网络的反向传播算法。
2. 卷积与池化的灵活应用。

### 难点

1. 理解卷积神经网络的反向传播算法。

### 教学目标

1. 掌握卷积神经网络反向传播算法的计算方法。
2. 掌握卷积层与池化层的应用。

### 